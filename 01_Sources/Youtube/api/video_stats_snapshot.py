"""
video_stats_snapshot.py

YouTube Data API ê¸°ë°˜ ì¡°íšŒìˆ˜/ì¢‹ì•„ìš”/ëŒ“ê¸€ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ê¸°.
- raw/search/*.json ì—ì„œ videoId ëª©ë¡ ë¡œë“œ
- videos.list ë¡œ í˜„ì¬ í†µê³„ ì¡°íšŒ
- raw/stats_snapshots/ ì— timestamp ê¸°ë°˜ìœ¼ë¡œ ì €ì¥

ì´ ìŠ¤ëƒ…ìƒ·ë“¤ì´ Î”views/Î”t, ìŠ¤íŒŒì´í¬ íƒì§€, ì•Œê³ ë¦¬ì¦˜ ê°ì§€ì˜ í•µì‹¬ ë°ì´í„°ê°€ ëœë‹¤.
"""

import json
import time
import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any

from youtube_client import YouTubeStatsClient  # ğŸ”¹ ê³µí†µ í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©


# ------------------------------
# ë””ë ‰í† ë¦¬ ì„¤ì •
# ------------------------------

HERE = Path(__file__).resolve()
PROJECT_ROOT = HERE.parents[1]   # .../01_Sources/Youtube
SEARCH_RAW_DIR = PROJECT_ROOT / "raw" / "search"
SNAPSHOT_DIR = PROJECT_ROOT / "raw" / "stats_snapshots"


# ------------------------------
# ë¡œê¹… ì„¤ì •
# ------------------------------

LOG_DIR = PROJECT_ROOT / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True)
LOG_FILE = LOG_DIR / "youtube_stats_snapshot.log"

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)


# ------------------------------
# raw/search â†’ videoId ë¡œë“œ
# ------------------------------

def load_video_ids_from_details() -> List[str]:
    """
    search_api.pyëŠ” detail_itemsë§Œ ì €ì¥í•˜ë¯€ë¡œ
    ì‹¤ì œ videoIdëŠ” item["id"]ì— stringìœ¼ë¡œ ì €ì¥ë¨.

    raw/search/*.json â†’ payload["items"] â†’ item["id"]
    """
    if not SEARCH_RAW_DIR.exists():
        raise FileNotFoundError(f"ê²€ìƒ‰ ê²°ê³¼ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {SEARCH_RAW_DIR}")

    video_ids: List[str] = []

    for json_path in SEARCH_RAW_DIR.glob("*.json"):
        try:
            with json_path.open("r", encoding="utf-8") as f:
                data = json.load(f)

            items = data.get("items", [])
            for item in items:
                vid = item.get("id")
                if isinstance(vid, str):
                    video_ids.append(vid)

        except Exception as e:
            logger.warning("ë¡œë“œ ì‹¤íŒ¨ %s: %s", json_path, e)

    # ì¤‘ë³µ ì œê±°
    return list(set(video_ids))


# ------------------------------
# ìŠ¤ëƒ…ìƒ· ì €ì¥
# ------------------------------

def save_snapshot(stats_items: List[Dict[str, Any]]) -> Path:
    SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.utcnow().strftime("%Y%m%dT%H%M%SZ")
    filename = f"{timestamp}__snapshot.json"

    out_path = SNAPSHOT_DIR / filename

    payload = {
        "snapshot_time_utc": timestamp,
        "items": stats_items
    }

    with out_path.open("w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    logger.info("ìŠ¤ëƒ…ìƒ· ì €ì¥ ì™„ë£Œ: %s", out_path)
    return out_path


# ------------------------------
# ì‹¤í–‰ í”Œë¡œìš°
# ------------------------------

def run_snapshot():
    logger.info("=== ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì‹œì‘ ===")

    video_ids = load_video_ids_from_details()

    if not video_ids:
        logger.warning("videoIdê°€ ì—†ìŒ. raw/search í´ë” í™•ì¸ í•„ìš”.")
        return

    logger.info("ëŒ€ìƒ ì˜ìƒ ìˆ˜: %d", len(video_ids))

    client = YouTubeStatsClient()

    # YouTube APIëŠ” id ìµœëŒ€ 50ê°œ ì œí•œ
    batch_size = 50
    all_items: List[Dict[str, Any]] = []

    for i in range(0, len(video_ids), batch_size):
        batch = video_ids[i:i+batch_size]
        data = client.get_video_details(batch)
        items = data.get("items", [])
        all_items.extend(items)
        time.sleep(1.0)  # API ë¶€ë‹´ ì™„í™”ìš© ë”œë ˆì´

    save_snapshot(all_items)

    logger.info("=== ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ ì¢…ë£Œ ===")


# ------------------------------
# ì§ì ‘ ì‹¤í–‰ ì‹œ
# ------------------------------

if __name__ == "__main__":
    run_snapshot()
